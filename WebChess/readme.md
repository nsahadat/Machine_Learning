# â™Ÿï¸ WebChess: Trainable Reinforcement Learning Chess Agent

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository contains both the **frontend** and **backend** to run a web-based chess game powered by a **Q-learning RL agent**. The agent improves over time by learning from its games against you. The backend is powered by **FastAPI**, and the frontend runs directly in your browser.

---

## ğŸš€ Features

- âœ… Play chess in your browser
- âœ… Reinforcement learning agent (Q-learning)
- âœ… FastAPI backend handles move logic and training
- âœ… SQLite database stores each game session
- âœ… The agent updates and retrains after every completed game
- âœ… The more you play, the smarter it gets!

---

## ğŸ“¦ Requirements

Install the required Python dependencies:

```bash
pip install -r requirements.txt
```

Make sure to create and activate a virtual environment first:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

---

## ğŸ§  How It Works

- Each time a game is played, the agent logs:
  - Board state
  - Move taken
  - Reward signal
  - Resulting state
- This data is stored in an SQLite database.
- After each session, the agent trains using these transitions.
- The updated model (`chess_rl_model.pth`) is saved and reloaded before the next game.

---

## ğŸ–¥ï¸ Running the Application

Open **two terminals**, navigate to your project folder, and do the following:

### ğŸ§© Step 1: Start the FastAPI Backend

```bash
uvicorn main:app --reload
```

This serves the RL agent API.

---

### ğŸŒ Step 2: Start the Frontend Server

In another terminal window:

```bash
python -m http.server 8000
```

---

### ğŸ”— Step 3: Open the App in Your Browser

Go to:

```
http://localhost:8000/frontend.html
```

Start playing â€” and observe how the agent improves over time!

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py                  # FastAPI backend (API, agent logic)
â”œâ”€â”€ trainAgentOnFly.py       # RL training code
â”œâ”€â”€ frontend.html            # Chess UI in the browser
â”œâ”€â”€ chess_rl_model.pth       # Saved model (optional, created after training)
â”œâ”€â”€ game_sessions.db         # SQLite DB of move history and rewards
â”œâ”€â”€ requirements.txt         # Required dependencies
â””â”€â”€ README.md                # You're here!
```

---

## ğŸ¤ Contributing

Contributions, bug reports, and feature suggestions are welcome! Fork this repo, open an issue, or submit a pull request.

---

## ğŸ“œ License

This project is open source and available under the [MIT License](https://opensource.org/licenses/MIT).

---

## ğŸ§ª Future Enhancements

- âœ… Smarter reward functions
- â³ Better state encodings (e.g., using board embeddings)
- â³ MCTS or deep Q-networks
- â³ Frontend polish with drag-and-drop UI
